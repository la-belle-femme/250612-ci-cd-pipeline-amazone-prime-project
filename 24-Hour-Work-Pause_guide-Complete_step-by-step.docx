# 24-Hour Work Pause Guide
## Safe Infrastructure Shutdown & Resume

### 🎯 Strategy: Partial Shutdown (Recommended)
**Save costs while preserving critical infrastructure**

---

## 📋 PHASE 1: PRE-SHUTDOWN PREPARATION (5 minutes)

### Step 1: Document Current State
```bash
# Verify everything is working before shutdown
kubectl get pods -A
kubectl get svc -A | grep LoadBalancer
kubectl get applications -n argocd
```

### Step 2: Save Critical Information
**Bookmark these URLs (they may change after restart):**
- **Prometheus:** http://a5bf131788af94a75b7328cf181e0c36-195901932.us-east-1.elb.amazonaws.com:9090
- **Grafana:** http://a29d0f23c26e44f70b949206e52cca54-596597616.us-east-1.elb.amazonaws.com
- **ArgoCD:** https://a0f45df08cb884ae08f7c9c2bb758927-1534938705.us-east-1.elb.amazonaws.com
- **App (Default):** http://a840871738585406d906f91731248bea-1232718192.us-east-1.elb.amazonaws.com
- **App (Production):** http://a78e2b4ca245c4f83b0b5aed30442658-561839786.us-east-1.elb.amazonaws.com

**Save Credentials:**
- **Grafana:** admin / prom-operator
- **ArgoCD:** admin / YsCZxl5hRYMblp5t

---

## 🔽 PHASE 2: SAFE SHUTDOWN SEQUENCE (10 minutes)

### Step 3: Scale Down Applications (Saves ~$0.05/hour)
```bash
# Scale down Amazon Prime Clone in default namespace
kubectl scale deployment amazon-prime-clone --replicas=0 -n default
echo "✅ Default namespace application scaled down"

# Scale down Amazon Prime Clone in production namespace  
kubectl scale deployment amazon-prime-clone --replicas=0 -n production
echo "✅ Production namespace application scaled down"

# Verify applications are scaling down
kubectl get pods -n default
kubectl get pods -n production
```

### Step 4: Scale Down Grafana (Saves ~$0.025/hour)
```bash
# Scale down Grafana (easy to restart, saves LoadBalancer cost)
kubectl scale deployment prometheus-stack-grafana --replicas=0 -n prometheus
echo "✅ Grafana scaled down"

# Verify Grafana is scaling down
kubectl get pods -n prometheus | grep grafana
```

### Step 5: Verify Shutdown Status
```bash
# Check that applications are stopped
echo "Checking application pods..."
kubectl get pods -n default | grep amazon-prime-clone || echo "Default app stopped ✅"
kubectl get pods -n production | grep amazon-prime-clone || echo "Production app stopped ✅"
kubectl get pods -n prometheus | grep grafana || echo "Grafana stopped ✅"

# Verify LoadBalancers are being cleaned up
echo "Checking LoadBalancer status..."
kubectl get svc -A | grep LoadBalancer
```

### Step 6: Stop Jenkins Instance (Optional - Saves ~$0.05/hour)
```bash
# Stop the Jenkins EC2 instance (optional additional savings)
aws ec2 stop-instances --instance-ids i-0ca32c89a19c57520
echo "✅ Jenkins instance stopped"
```

---

## 💰 PHASE 3: COST VERIFICATION

### Step 7: Confirm Cost Savings
**What's Still Running (Protected Infrastructure):**
- ✅ **EKS Cluster:** amazon-prime-eks (~$0.10/hour)
- ✅ **EKS Nodes:** 2x t3.medium (~$0.192/hour)
- ✅ **ArgoCD:** GitOps platform (~$0.025/hour)
- ✅ **Prometheus:** Monitoring engine (~$0.025/hour)

**What's Stopped (Cost Savings):**
- ❌ **Application LoadBalancers:** 2x (~$0.05/hour saved)
- ❌ **Grafana LoadBalancer:** 1x (~$0.025/hour saved)
- ❌ **Jenkins Instance:** 1x (~$0.05/hour saved - if stopped)

**Total Hourly Cost:**
- **Before:** ~$0.392/hour (~$9.40/24 hours)
- **After:** ~$0.267/hour (~$6.40/24 hours)
- **Savings:** ~$3.00 per 24 hours (32% reduction)

---

## 🛡️ PHASE 4: FINAL VERIFICATION (5 minutes)

### Step 8: Document What's Preserved
```bash
# Verify critical infrastructure is still running
echo "=== INFRASTRUCTURE STATUS ==="
kubectl get nodes
kubectl get namespaces
kubectl get pods -n argocd
kubectl get pods -n prometheus | grep -v grafana

# Verify ArgoCD applications are still configured
kubectl get applications -n argocd
```

### Step 9: Save Current Configuration
```bash
# Export current state for reference
kubectl get all -A > ~/cluster-state-backup.yaml
kubectl get applications -n argocd -o yaml > ~/argocd-apps-backup.yaml
echo "✅ Configuration backup saved"
```

---

## 🚀 PHASE 5: RESUME PROCEDURE (For 24 hours later)

### When You Return - Resume Steps:

#### Step 1: Reconnect to Infrastructure
```bash
# Update kubectl configuration
aws eks update-kubeconfig --region us-east-1 --name amazon-prime-eks

# Verify cluster is accessible
kubectl get nodes
kubectl get pods -n argocd
```

#### Step 2: Start Jenkins (If Stopped)
```bash
# Start Jenkins instance if you stopped it
aws ec2 start-instances --instance-ids i-0ca32c89a19c57520

# Wait 2-3 minutes for startup, then check
aws ec2 describe-instances --instance-ids i-0ca32c89a19c57520 --query 'Reservations[*].Instances[*].State.Name'
```

#### Step 3: Scale Up Applications
```bash
# Scale up Amazon Prime Clone applications
kubectl scale deployment amazon-prime-clone --replicas=2 -n default
kubectl scale deployment amazon-prime-clone --replicas=2 -n production

# Scale up Grafana
kubectl scale deployment prometheus-stack-grafana --replicas=1 -n prometheus

echo "✅ All applications scaling back up"
```

#### Step 4: Wait for LoadBalancers
```bash
# Wait 3-5 minutes for LoadBalancers to provision
echo "Waiting for LoadBalancers to provision..."
sleep 180

# Check LoadBalancer status
kubectl get svc -A | grep LoadBalancer
```

#### Step 5: Get New URLs
```bash
# Get updated URLs (they may have changed)
echo "=== NEW ACCESS URLS ==="
echo "Prometheus: http://$(kubectl get svc -n prometheus prometheus-stack-kube-prom-prometheus -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'):9090"
echo "Grafana: http://$(kubectl get svc -n prometheus prometheus-stack-grafana -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')"
echo "ArgoCD: https://$(kubectl get svc -n argocd argocd-server -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')"
echo "App (Default): http://$(kubectl get svc -n default amazon-prime-clone-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')"
echo "App (Production): http://$(kubectl get svc -n production amazon-prime-clone-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')"
```

#### Step 6: Verify Everything is Working
```bash
# Check all pods are running
kubectl get pods -A | grep -E "(amazon-prime-clone|grafana|argocd|prometheus)"

# Test one application URL
curl -I $(kubectl get svc -n production amazon-prime-clone-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}') || echo "Still starting up..."
```

---

## ✅ SUCCESS CHECKLIST

### Before Pausing:
- [ ] Applications scaled to 0 replicas
- [ ] Grafana scaled to 0 replicas  
- [ ] Jenkins instance stopped (optional)
- [ ] Critical URLs and credentials saved
- [ ] ArgoCD and Prometheus still running
- [ ] Cluster nodes remain active

### After Resuming:
- [ ] kubectl reconnected successfully
- [ ] Applications scaled back to 2 replicas
- [ ] Grafana running and accessible
- [ ] All LoadBalancers have external IPs
- [ ] ArgoCD applications show "Healthy" status
- [ ] Monitoring dashboards loading correctly

---

## 💡 Pro Tips

### Cost Optimization:
- **This saves ~$3/day** while preserving your complex infrastructure
- **Resume time: 5-10 minutes** vs 60-90 minutes for full recreation
- **Zero configuration loss** - everything preserved

### Portfolio Protection:
- **Your achievement remains intact** - can demonstrate anytime after resume
- **Screenshots and metrics** already captured prove your capabilities
- **Infrastructure complexity** preserved for continued learning

### Emergency Recovery:
- **If anything goes wrong:** Your Terraform code and Jenkins pipelines can recreate everything in 60-90 minutes
- **GitHub repository** contains all configuration as code
- **This chat** contains all URLs, credentials, and procedures

---

## 🎯 Ready to Pause?

**Estimated Time:**
- **Shutdown:** 10 minutes
- **Resume:** 10 minutes  
- **Cost savings:** ~$3.00 over 24 hours

**Your enterprise DevOps platform will be safely preserved and ready for your return!**